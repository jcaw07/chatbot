{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcaw07/chatbot/blob/main/Gemini_Redis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiHV6ip2f5id"
      },
      "source": [
        "# LLM Reference Architecture using Redis & Google Cloud Platform\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/RedisVentures/redis-google-llms/blob/main/BigQuery_Palm_Redis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This notebook serves as a getting started guide for working with LLMs on Google Cloud Platform with Redis Enterprise.\n",
        "\n",
        "## Intro\n",
        "Google's Vertex AI has expanded its capabilities by introducing [Generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview). This advanced technology comes with a specialized [in-console studio experience](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/quickstart), a [dedicated API](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart) and [Python SDK](https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) designed for deploying and managing instances of Google's powerful Gemini language models.\n",
        "\n",
        "Redis Enterprise offers robust vector database features, with an efficient API for vector index creation, management, distance metric selection, similarity search, and hybrid filtering. When coupled with its versatile data structures - including lists, hashes, JSON, and sets - Redis Enterprise shines as the optimal solution for crafting high-quality Large Language Model (LLM)-based applications. It embodies a streamlined architecture and exceptional performance, making it an instrumental tool for production environments.\n",
        "\n",
        "Below we will work through several design patterns with Vertex AI LLMs and Redis Enterprise that will ensure optimal production performance.\n",
        "\n",
        "___\n",
        "## Contents\n",
        "- Setup\n",
        "    1. Prerequisites\n",
        "    2. Obtain Dataset\n",
        "    3. Generate Embeddings\n",
        "    4. Create Index\n",
        "    5. Query\n",
        "- Building a RAG Pipeline from scratch\n",
        "- Demo\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK2rWODkw-kX"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37rbBPKdL09o"
      },
      "source": [
        "## 1. Prerequisites\n",
        "Before we begin, we must install some required libraries, authenticate with Google, create a Redis database, and initialize other required components.\n",
        "\n",
        "### Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc-IxYu3wnQm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "149fc2c9-e79f-473e-a9e1-6b0deb013256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/RedisVentures/redisvl.git\n",
            "  Cloning https://github.com/RedisVentures/redisvl.git to /tmp/pip-req-build-4dhh4n5b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/RedisVentures/redisvl.git /tmp/pip-req-build-4dhh4n5b\n",
            "  Resolved https://github.com/RedisVentures/redisvl.git to commit f297133e00dfb7a8e1a69797a9ce1d06368233da\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.44.0)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured[pdf]\n",
            "  Downloading unstructured-0.12.6-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-4.23.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from redisvl==0.1.2) (1.25.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from redisvl==0.1.2) (6.0.1)\n",
            "Collecting coloredlogs (from redisvl==0.1.2)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis>=5.0.0 (from redisvl==0.1.2)\n",
            "  Downloading redis-5.0.3-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.8/251.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from redisvl==0.1.2) (2.6.4)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from redisvl==0.1.2) (8.2.3)\n",
            "Requirement already satisfied: tabulate<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from redisvl==0.1.2) (0.9.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Collecting backoff==2.2.1 (from unstructured[pdf])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.12.3)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2024.2.2)\n",
            "Requirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.3.2)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (8.1.7)\n",
            "Collecting dataclasses-json-speakeasy==0.5.11 (from unstructured[pdf])\n",
            "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
            "Collecting emoji==2.10.1 (from unstructured[pdf])\n",
            "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype==1.2.0 (from unstructured[pdf])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.6)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.3.2)\n",
            "Collecting jsonpath-python==1.0.6 (from unstructured[pdf])\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting langdetect==1.0.9 (from unstructured[pdf])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lxml==5.1.0 (from unstructured[pdf])\n",
            "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow==3.20.2 (from unstructured[pdf])\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions==1.0.0 (from unstructured[pdf])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.8.1)\n",
            "Collecting numpy (from redisvl==0.1.2)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=14.3 (from google-cloud-aiplatform)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.8.2)\n",
            "Collecting python-iso639==2024.2.7 (from unstructured[pdf])\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic==0.4.27 (from unstructured[pdf])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Collecting rapidfuzz==3.6.1 (from unstructured[pdf])\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex==2023.12.25 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2023.12.25)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: soupsieve==2.5 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.5)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.66.2)\n",
            "Collecting typing-extensions==4.9.0 (from unstructured[pdf])\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting typing-inspect==0.9.0 (from unstructured[pdf])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting unstructured-client==0.18.0 (from unstructured[pdf])\n",
            "  Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
            "Collecting urllib3==1.26.18 (from unstructured[pdf])\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt==1.16.0 (from unstructured[pdf])\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.3 (from unstructured[pdf])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi==1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.2.0)\n",
            "Collecting cryptography==42.0.2 (from unstructured[pdf])\n",
            "  Downloading cryptography-42.0.2-cp39-abi3-manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.12.1)\n",
            "Collecting deprecated==1.2.14 (from unstructured[pdf])\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting effdet==0.4.1 (from unstructured[pdf])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock==3.13.1 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.13.1)\n",
            "Collecting flatbuffers==23.5.26 (from unstructured[pdf])\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting fonttools==4.49.0 (from unstructured[pdf])\n",
            "  Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2024.2.0 (from unstructured[pdf])\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub==0.20.3 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.20.3)\n",
            "Collecting humanfriendly==10.0 (from unstructured[pdf])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources==6.1.1 (from unstructured[pdf])\n",
            "  Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
            "Collecting iopath==0.1.10 (from unstructured[pdf])\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.1.3)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.4.5)\n",
            "Collecting layoutparser[layoutmodels,tesseract]==0.3.4 (from unstructured[pdf])\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markupsafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.1.5)\n",
            "Collecting matplotlib==3.7.2 (from unstructured[pdf])\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.2.1)\n",
            "Collecting omegaconf==2.3.0 (from unstructured[pdf])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.15.0 (from unstructured[pdf])\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime==1.15.1 (from unstructured[pdf])\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python==4.8.0.76 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.8.0.76)\n",
            "Collecting pandas==2.2.0 (from unstructured[pdf])\n",
            "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image==1.17.0 (from unstructured[pdf])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer-six==20221105 (from unstructured[pdf])\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfplumber==0.10.4 (from unstructured[pdf])\n",
            "  Downloading pdfplumber-0.10.4-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pikepdf==8.11.0 (from unstructured[pdf])\n",
            "  Downloading pikepdf-8.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow==10.2.0 (from unstructured[pdf])\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow-heif==0.15.0 (from unstructured[pdf])\n",
            "  Downloading pillow_heif-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker==2.8.2 (from unstructured[pdf])\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-aiplatform)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools==2.0.7 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.0.7)\n",
            "Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.21)\n",
            "Collecting pyparsing==3.0.9 (from unstructured[pdf])\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf==4.0.1 (from unstructured[pdf])\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdfium2==4.27.0 (from unstructured[pdf])\n",
            "  Downloading pypdfium2-4.27.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract==0.3.10 (from unstructured[pdf])\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting python-multipart==0.0.9 (from unstructured[pdf])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting pytz==2024.1 (from unstructured[pdf])\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors==0.3.2 (from unstructured[pdf])\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from unstructured[pdf])\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.12)\n",
            "Collecting timm==0.9.12 (from unstructured[pdf])\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers==0.15.2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.15.2)\n",
            "Collecting torch==2.2.0 (from unstructured[pdf])\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.17.0 (from unstructured[pdf])\n",
            "  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.37.1 (from unstructured[pdf])\n",
            "  Downloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata==2024.1 (from unstructured[pdf])\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured-inference==0.7.23 (from unstructured[pdf])\n",
            "  Downloading unstructured_inference-0.7.23-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured-pytesseract==0.3.12 (from unstructured[pdf])\n",
            "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
            "Collecting zipp==3.17.0 (from unstructured[pdf])\n",
            "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->unstructured[pdf]) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->unstructured[pdf])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.14.0 (from gradio)\n",
            "  Downloading gradio_client-0.14.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.4/312.4 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.3.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==0.14.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->redisvl==0.1.2) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->redisvl==0.1.2) (2.16.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.5.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: redisvl, antlr4-python3-runtime, iopath, langdetect, ffmpy\n",
            "  Building wheel for redisvl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for redisvl: filename=redisvl-0.1.2-py3-none-any.whl size=57454 sha256=a45b58ffb93dc85f08a61ece464f9a5b197e136cefa2011a2d6b06bb032ea972\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ergx5qxc/wheels/f7/d4/0c/dba135fb25675ab2d46f83593f712d13da42989b6dde2caaea\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d5a197cab3f25dbac6da056426adc2434c1c0ea578356300efe9b7c1605f440a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=e2d0caf479e2de68fefbcc2643770b8d151071cf7042a421cd398402a9fea0b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=f35abcae8a0f2a533ea8b3eb266cc15c9f42e1df0e8190432b635c64262b0971\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=4fb5835f1951f028d7f4afd4464e5e25b02b61b9f444ea600945228448b94015\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built redisvl antlr4-python3-runtime iopath langdetect ffmpy\n",
            "Installing collected packages: safetensors, pytz, pydub, flatbuffers, filetype, ffmpy, antlr4-python3-runtime, zipp, wrapt, websockets, urllib3, tzdata, typing-extensions, tomlkit, shellingham, semantic-version, ruff, redis, rapidfuzz, python-multipart, python-magic, python-iso639, pypdfium2, pypdf, pyparsing, protobuf, portalocker, pillow, packaging, orjson, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mypy-extensions, lxml, langdetect, jsonpointer, jsonpath-python, importlib-resources, humanfriendly, h11, fsspec, fonttools, emoji, colorama, backoff, aiofiles, uvicorn, unstructured-pytesseract, typing-inspect, starlette, scipy, pytesseract, pillow-heif, pdf2image, pandas, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, jsonpatch, iopath, httpcore, deprecated, cryptography, coloredlogs, pikepdf, pdfminer-six, onnxruntime, nvidia-cusolver-cu12, matplotlib, httpx, dataclasses-json-speakeasy, dataclasses-json, unstructured-client, torch, redisvl, pdfplumber, langsmith, gradio-client, fastapi, unstructured, transformers, torchvision, layoutparser, langchain-core, gradio, timm, langchain-text-splitters, langchain-community, langchain, effdet, unstructured-inference\n",
            "\u001b[33m  WARNING: The script filetype is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script pypdfium2 is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script f2py is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script humanfriendly is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script uvicorn is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script pytesseract is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script pytesseract is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts backend-test-tools, check-model and check-node are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script rvl is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script pdfplumber is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script unstructured-ingest is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.26.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.0 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.0 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 antlr4-python3-runtime-4.9.3 backoff-2.2.1 colorama-0.4.6 coloredlogs-15.0.1 cryptography-42.0.2 dataclasses-json-0.6.4 dataclasses-json-speakeasy-0.5.11 deprecated-1.2.14 effdet-0.4.1 emoji-2.10.1 fastapi-0.110.0 ffmpy-0.3.2 filetype-1.2.0 flatbuffers-23.5.26 fonttools-4.49.0 fsspec-2024.2.0 gradio-4.23.0 gradio-client-0.14.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 humanfriendly-10.0 importlib-resources-6.1.1 iopath-0.1.10 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langdetect-1.0.9 langsmith-0.1.31 layoutparser-0.3.4 lxml-5.1.0 marshmallow-3.20.2 matplotlib-3.7.2 mypy-extensions-1.0.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnx-1.15.0 onnxruntime-1.15.1 orjson-3.9.15 packaging-23.2 pandas-2.2.0 pdf2image-1.17.0 pdfminer-six-20221105 pdfplumber-0.10.4 pikepdf-8.11.0 pillow-10.2.0 pillow-heif-0.15.0 portalocker-2.8.2 protobuf-4.23.4 pydub-0.25.1 pyparsing-3.0.9 pypdf-4.0.1 pypdfium2-4.27.0 pytesseract-0.3.10 python-iso639-2024.2.7 python-magic-0.4.27 python-multipart-0.0.9 pytz-2024.1 rapidfuzz-3.6.1 redis-5.0.3 redisvl-0.1.2 ruff-0.3.4 safetensors-0.3.2 scipy-1.10.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 timm-0.9.12 tomlkit-0.12.0 torch-2.2.0 torchvision-0.17.0 transformers-4.37.1 typing-extensions-4.9.0 typing-inspect-0.9.0 tzdata-2024.1 unstructured-0.12.6 unstructured-client-0.18.0 unstructured-inference-0.7.23 unstructured-pytesseract-0.3.12 urllib3-1.26.18 uvicorn-0.29.0 websockets-11.0.3 wrapt-1.16.0 zipp-3.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "pydevd_plugins"
                ]
              },
              "id": "46c89e86fdd8412ebf658e939d25ceaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install -U git+https://github.com/RedisVentures/redisvl.git google-cloud-aiplatform langchain unstructured[pdf] gradio --upgrade --user\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr_IviwqFS7K"
      },
      "source": [
        "### Using Free Redis Cloud account on GCP\n",
        "You can also use Forever Free instance of Redis Cloud. To activate it:\n",
        "- Head to https://redis.com/try-free/\n",
        "- Register (using gmail-based registration is the easiest)\n",
        "- Create New Subscription\n",
        "- Use the following options:\n",
        "    - Fixed plan, Google Cloud\n",
        "    - New 30Mb Free database\n",
        "- Create new RedisStack DB\n",
        "\n",
        "If you are registering at Redis Cloud for the first time - the last few steps would be performed for you by default. Capture the host, port and default password of the new database. You can use these instead of default `localhost` based in the following code block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5kx9ePDwwp6"
      },
      "source": [
        "^^^ If prompted press the Restart button to restart the kernel. ^^^\n",
        "\n",
        "### Install Redis locally (optional)\n",
        "If you have a Redis db running elsewhere with [Redis Stack](https://redis.io/docs/about/about-stack/) installed, you don't need to run it on this machine. You can skip to the \"Connect to Redis server\" step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs4KZURX4XpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821e81ea-6a0c-4ac8-b67e-3b6115927dbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb jammy main\n",
            "Starting redis-stack-server, database path /var/lib/redis-stack\n"
          ]
        }
      ],
      "source": [
        "%%sh\n",
        "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
        "sudo apt-get update  > /dev/null 2>&1\n",
        "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "redis-stack-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvDp8WNz4XpU"
      },
      "source": [
        "### Connect to Redis server\n",
        "Replace the connection params below with your own if you are connecting to an external Redis instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duCyNgfZ4XpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c529857-0a90-4df3-cdef-b56e7cba1155"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import redis\n",
        "\n",
        "# Redis connection params\n",
        "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\") #\"redis-12110.c82.us-east-1-2.ec2.cloud.redislabs.com\"\n",
        "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")      #12110\n",
        "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")  #\"pobhBJP7Psicp2gV0iqa2ZOc1WdXXXXX\"\n",
        "\n",
        "# Create Redis client\n",
        "redis_client = redis.Redis(\n",
        "  host=REDIS_HOST,\n",
        "  port=REDIS_PORT,\n",
        "  password=REDIS_PASSWORD\n",
        ")\n",
        "\n",
        "# Test connection\n",
        "redis_client.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Rrz76w96dF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afbc1c8-9fb7-4e5c-fa3a-b70172b3ac58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Clear Redis database (optional)\n",
        "redis_client.flushdb()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpjxW-kou-FY"
      },
      "source": [
        "### Authenticate to Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeTJb51SKs_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8bad23-33e5-402e-b2f8-4d3b31ecd992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yil6twAvIuH"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# input your GCP project ID and region for Vertex AI\n",
        "PROJECT_ID = \"redis-business-development\" #getpass(\"PROJECT_ID:\") #'central-beach-194106'\n",
        "REGION = input(\"REGION:\") #'us-central1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vDGqjHmVgjB"
      },
      "source": [
        "## 2. Obtain dataset\n",
        "\n",
        "Below pull the dataset from ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Procure a dataset - downloading a publication from IRS\n",
        "!mkdir resources\n",
        "!wget https://www.irs.gov/pub/irs-pdf/p5718.pdf -P resources/"
      ],
      "metadata": {
        "id": "Pxshas3XpgdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d44ed74-517a-4133-93f0-60ae275670cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-26 00:27:51--  https://www.irs.gov/pub/irs-pdf/p5718.pdf\n",
            "Resolving www.irs.gov (www.irs.gov)... 23.14.150.146, 2600:1408:7:19f::f50, 2600:1408:7:197::f50\n",
            "Connecting to www.irs.gov (www.irs.gov)|23.14.150.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8749823 (8.3M) [application/pdf]\n",
            "Saving to: ‘resources/p5718.pdf’\n",
            "\n",
            "p5718.pdf           100%[===================>]   8.34M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-26 00:27:51 (79.3 MB/s) - ‘resources/p5718.pdf’ saved [8749823/8749823]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kh0ObD4xZtK"
      },
      "source": [
        "### Create text embeddings with Vertex AI embedding model\n",
        "Use the [Vertex AI API for text embeddings](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings), developed by Google.\n",
        "\n",
        "> Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
        "> - **Semantic search**: Search text ranked by semantic similarity.\n",
        "> - **Recommendation**: Return items with text attributes similar to the given text.\n",
        "> - **Classification**: Return the class of items whose text attributes are similar to the given text.\n",
        "> - **Clustering**: Cluster items whose text attributes are similar to the given text.\n",
        "> - **Outlier Detection**: Return items where text attributes are least related to the given text.\n",
        "\n",
        "The `textembedding-gecko` model accepts a maximum of 3,072 input tokens (i.e. words) and outputs 768-dimensional vector embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3o_9ehYuEpA"
      },
      "source": [
        "### Set up embeddings\n",
        "We define a helper function to create embeddings from a list of texts convert them to a byte string for efficient storage in Redis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrpKY4W5yb0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "eddbfad7-22f7-4d32-ab48-09094bc24228"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "PermissionDenied",
          "evalue": "403 Your application is authenticating by using local Application Default Credentials. The aiplatform.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"aiplatform.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/32555940559\"\n}\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         )\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Your application is authenticating by using local Application Default Credentials. The aiplatform.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.167.95:443 {grpc_message:\"Your application is authenticating by using local Application Default Credentials. The aiplatform.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds .\", grpc_status:7, created_time:\"2024-03-26T00:29:18.574269665+00:00\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0371ba054f9e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mredisvl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVertexAITextVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m vectorizer = VertexAITextVectorizer(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"textembedding-gecko@003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mapi_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"project_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"location\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mREGION\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/redisvl/utils/vectorize/text/vertexai.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, api_config)\u001b[0m\n\u001b[1;32m     94\u001b[0m             )\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextEmbeddingModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_model_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/_model_garden/_model_garden_models.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterface_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mauth_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAuthError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mauth_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAuthError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredential_exception_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/_model_garden/_model_garden_models.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(interface_class, model_name, publisher_model, tuned_vertex_model)\u001b[0m\n\u001b[1;32m    206\u001b[0m             )\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         model_info = _get_model_info(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mschema_to_class_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minterface_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_INSTANCE_SCHEMA_URI\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minterface_class\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/_model_garden/_model_garden_models.py\u001b[0m in \u001b[0;36m_get_model_info\u001b[0;34m(model_id, schema_to_class_map, interface_class, publisher_model_res, tuned_vertex_model)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpublisher_model_res\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         publisher_model_res = (\n\u001b[0;32m--> 124\u001b[0;31m             _publisher_models._PublisherModel(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             )._gca_resource\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/_publisher_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, resource_name, project, location, credentials)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 )\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         self._gca_resource = getattr(self.api_client, self._getter_method)(\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_resource_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DEFAULT_RETRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1/services/model_garden_service/client.py\u001b[0m in \u001b[0;36mget_publisher_model\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    767\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDenied\u001b[0m: 403 Your application is authenticating by using local Application Default Credentials. The aiplatform.googleapis.com API requires a quota project, which is not set by default. To learn how to set your quota project, see https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds . [reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"aiplatform.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/32555940559\"\n}\n]"
          ]
        }
      ],
      "source": [
        "from redisvl.utils.vectorize import VertexAITextVectorizer\n",
        "\n",
        "vectorizer = VertexAITextVectorizer(\n",
        "    model = \"textembedding-gecko@003\",\n",
        "    api_config = {\"project_id\": PROJECT_ID, \"location\": REGION}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFHIY351eDc"
      },
      "source": [
        "## 3. Generate Embeddings\n",
        "The next step is to create chunks of the pdf and then embed each chunk as a vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzkRiknVXOtc"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "doc = \"resources/p5718.pdf\"\n",
        "\n",
        "# set up the file loader/extractor and text splitter to create chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2500, chunk_overlap=0\n",
        ")\n",
        "loader = UnstructuredFileLoader(\n",
        "    doc, mode=\"single\", strategy=\"fast\"\n",
        ")\n",
        "\n",
        "# extract, load, and make chunks\n",
        "chunks = loader.load_and_split(text_splitter)\n",
        "\n",
        "print(\"Done preprocessing. Created\", len(chunks), \"chunks of the original pdf\", doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OETsrYvfuzmX"
      },
      "outputs": [],
      "source": [
        "# Embed each chunk content\n",
        "embeddings = vectorizer.embed_many([chunk.page_content for chunk in chunks], as_buffer=True)\n",
        "\n",
        "# Check to make sure we've created enough embeddings, 1 per document chunk\n",
        "len(embeddings) == len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGVt7-DNr80e"
      },
      "source": [
        "## 4. Create Index\n",
        "\n",
        "Now that we have created embeddings that represent the text in our dataset, we will create an index that enables efficient search over the embeddings.\n",
        "\n",
        "**Why do we need to enable search???**\n",
        "Using Redis for vector search allows us to retrieve chunks of text data that are **similar** or **relevant** to an input question or query. This will be extremely helpful for our sample generative ai / LLM application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mNa5LNn4XpX"
      },
      "outputs": [],
      "source": [
        "from redisvl.schema import IndexSchema\n",
        "from redisvl.index import SearchIndex\n",
        "\n",
        "\n",
        "index_name = \"redisvl\"\n",
        "\n",
        "schema = IndexSchema.from_dict({\n",
        "  \"index\": {\n",
        "    \"name\": index_name,\n",
        "    \"prefix\": \"chunk\"\n",
        "  },\n",
        "  \"fields\": [\n",
        "    {\n",
        "        \"name\": \"chunk_id\",\n",
        "        \"type\": \"tag\",\n",
        "        \"attrs\": {\n",
        "            \"sortable\": True\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"content\",\n",
        "        \"type\": \"text\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"text_embedding\",\n",
        "        \"type\": \"vector\",\n",
        "        \"attrs\": {\n",
        "            \"dims\": vectorizer.dims,\n",
        "            \"distance_metric\": \"cosine\",\n",
        "            \"algorithm\": \"flat\",\n",
        "            \"datatype\": \"float32\"\n",
        "        }\n",
        "    }\n",
        "  ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an index from schema and the client\n",
        "index = SearchIndex(schema, redis_client)\n",
        "index.create(overwrite=True, drop=True)"
      ],
      "metadata": {
        "id": "cNjHD3D94_Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOzL5qB-uzrE"
      },
      "outputs": [],
      "source": [
        "# Load expects an iterable of dictionaries\n",
        "data = [\n",
        "    {\n",
        "        'chunk_id': f'{i}',\n",
        "        'content': chunk.page_content,\n",
        "        'text_embedding': embeddings[i]\n",
        "    } for i, chunk in enumerate(chunks)\n",
        "]\n",
        "\n",
        "# RedisVL handles batching automatically\n",
        "keys = index.load(data, id_field=\"chunk_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6CmHY3-6wB1"
      },
      "source": [
        "## 5. Query\n",
        "Now we can use RedisVL to perform a variety of vector search operations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from redisvl.query import VectorQuery\n",
        "\n",
        "query = \"What is TCC?\"\n",
        "\n",
        "query_embedding = vectorizer.embed(query)\n",
        "\n",
        "vector_query = VectorQuery(\n",
        "    vector=query_embedding,\n",
        "    vector_field_name=\"text_embedding\",\n",
        "    num_results=3,\n",
        "    return_fields=[\"chunk_id\", \"content\"],\n",
        "    return_score=True\n",
        ")\n",
        "\n",
        "# show the raw redis query\n",
        "str(vector_query)"
      ],
      "metadata": {
        "id": "d9HKH8kO5T3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5018c62f-4d44-4ce2-e582-846aa393449f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*=>[KNN 3 @text_embedding $vector AS vector_distance] RETURN 3 chunk_id content vector_distance SORTBY vector_distance ASC DIALECT 2 LIMIT 0 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# execute the query with RedisVL\n",
        "index.query(vector_query)"
      ],
      "metadata": {
        "id": "W_-AlXmE5dUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44182d8a-2d91-417c-c579-9538c793afff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'chunk:11',\n",
              "  'vector_distance': '0.344000458717',\n",
              "  'chunk_id': '11',\n",
              "  'content': 'When your IRIS Application for TCC is approved and completed, a five-character alphanu- meric TCC that begins with the letter ‘D’ will be assigned to your business. An approval letter will be sent via United States Postal Service (USPS) to the address listed on the application, informing you of your TCC. You can also sign into your IRIS Application for TCC to view your TCCs on the Application Summary page.\\n\\n13\\n\\nPublication 5718\\n\\nIf your application is in Completed status for more than 45 days and your TCC has not been assigned, contact the Help Desk.\\n\\n1.3.7 Revise Current TCC Information\\n\\nAs changes occur, you must update and maintain your IRIS TCC Application. Some changes will require all ROs or Authorized Delegates (ADs) on the application to re-sign the Appli- cation Submission page. Below are examples of when an application would need to be re-signed (this list is not all inclusive):\\n\\nFirm’s DBA Name change\\n\\nRole changes or additions\\n\\nAdd, delete or change RO and/or AD\\n\\nNote: Changes submitted on an IRIS TCC Application do not change the address of IRS tax records just as a change of address to IRS tax records does not automatically update infor- mation on an IRIS TCC Application.\\n\\nChanges that require a firm to acquire a new Employer Identification Number (EIN) require a new IRIS TCC Application. Firms that change their form of organization, such as from a sole proprietorship to a corporation, generally require the firm to acquire a new EIN.\\n\\n1.3.8 Deleted TCCs\\n\\nYour TCCs will remain valid if you transmit information returns or extensions of time to file. If you don’t use your TCC for three consecutive years, your TCC will be deleted. Once your TCC is deleted it cannot be reactivated. You’ll need to submit a new IRIS Application for TCC.\\n\\n1.4 Transmitter and Issuer TCCs\\n\\nDepending on the roles selected on the application, one or more TCCs will be assigned. Each TCC will have an indicator of Test “T” or Production “P” and status of Active, Inactive, or Dropped. Transmitters and Issuers are issued a TCC in Test “T” status until required Communication Testing is conducted in the ATS environment and passed. Once Commu- nication Testing is passed, the Transmitter should contact the Help Desk to request to be moved to Production “P” status. For more information about Communication Testing for Transmitters, refer to Publication 5719, Information Returns Intake System (IRIS) Test Package for Information Returns.\\n\\n1.5 Software Developer TCCs'},\n",
              " {'id': 'chunk:9',\n",
              "  'vector_distance': '0.344615459442',\n",
              "  'chunk_id': '9',\n",
              "  'content': 'Select the role of Transmitter on your application. Note: The TCC for a Transmitter can be used to transmit your own returns and others. You may not use an Issuer TCC to transmit information returns for others.\\n\\n11\\n\\nPublication 5718\\n\\n1.3.3 Third-Party Transmitters\\n\\nIf you do not have an in-house programmer familiar with XML or do not wish to purchase A2A software that is certified to support the information returns that you plan to file, you can file through a Third-Party Transmitter or use the online Taxpayer Portal. Visit www.irs.gov/ iris for additional information.\\n\\nOnly those persons listed as an Authorized User on the IRIS Application for TCC qualify to receive information about a Receipt ID associated with a TCC listed on that application.\\n\\nIf your Third-Party Transmitter needs technical assistance regarding a Receipt ID associated with records that were submitted on behalf of your organization, they should contact the Help Desk.\\n\\nWhen filing through a Third-Party Transmitter obtain the following for each submission filed on your behalf:\\n\\nA copy of all electronic records within each submission, along with the Receipt ID for the transmission in which they were filed.\\n\\nThe transmission Acknowledgement that includes the Status that is returned when processing is complete (Accepted, Accepted With Errors, Partially Accepted, Rejected) and a detailed list of errors, if any.\\n\\nNote: The items cited above are critical to your ability to make corrections should your Third- party Transmitter go out of business or be otherwise unavailable to file corrections on your behalf.\\n\\n1.3.4 Things you need to know before completing the IRIS\\n\\nA responsible official (RO) initiates and submits the IRIS Application for TCC electronically. Each RO must sign the terms of agreement using their five-digit PIN they created when they initially accessed the system. An application will receive a tracking number after saving it. Completing the application in a single session isn’t a requirement.\\n\\nThe following information is necessary to complete each application:\\n\\nFirm’s business structure\\n\\nFirm’s (EIN) (the system doesn’t allow firms to use a Social Security Number (SSN) or Individual Taxpayer Identification Number (ITIN)\\n\\nFirm’s legal business name and business type\\n\\nFirm’s doing business as name when it’s different from the legal business name\\n\\nBusiness phone (phone country code and phone number)\\n\\nBusiness address (this must be a physical location, not a post office box)'},\n",
              " {'id': 'chunk:7',\n",
              "  'vector_distance': '0.346010804176',\n",
              "  'chunk_id': '7',\n",
              "  'content': 'IRIS uses QuickAlerts, an IRS e-mail service, to disseminate information quickly regarding IRIS issues to subscribers. This service keeps tax professionals up to date on IRIS issues throughout the year, with emphasis on issues during the filing season. After subscribing, customers will receive “round the clock” communication issues such as electronic specifica- tions and system information needed for Software Developers and Transmitters to transmit to IRS. New subscribers may sign up through the “subscription page” link located on the QuickAlerts “more” e-file Benefits for Tax Professionals page.\\n\\n9\\n\\nPublication 5718\\n\\n1.3 Registration and Application Process\\n\\nExternal users must register with the current IRS credential service provider and complete the IRIS Application for Transmitter Control Code (TCC) to submit transmissions using the IRIS intake platform. Information returns filed through the IRIS A2A system cannot be filed using any other intake platform TCC. These include:\\n\\ne-File Application (MeF)\\n\\nAffordable Care Act (ACA) Application for TCC (AIR)\\n\\nPartnership Bipartisan Budget Act (PBBA) Application for TCC\\n\\n\\n\\nInformation Returns (IR) Application for TCC (FIRE)\\n\\n\\n\\nIRIS TCC for the Taxpayer Portal\\n\\n1.3.1 Registration\\n\\nBefore completing the IRIS Application for TCC, each user must create an account or sign-in using their existing credentials to validate their identities using the latest authentication process.\\n\\nFor more information, please visit How to register for IRS online self-help tools | Internal Revenue Service.\\n\\n1.3.2 Who should apply for an IRIS TCC\\n\\nIf you are transmitting information returns to the IRS or if you are developing software to file information returns electronically, you must apply for one or more TCCs using the IRIS Appli- cation for TCC available online. A single application can be used to apply for multiple roles and the necessary TCCs. The IRS encourages transmitters who file for multiple issuers to submit one application and use the assigned TCC for all issuers. The purpose of the TCC is to identify the business acting as the transmitter of the file. As a transmitter, you may transmit files for as many companies as you need to under one TCC. The IRIS Application for TCC contains three separate roles: Software Developer, Transmitter, and Issuer. Complete the IRIS Application for TCC if your firm or organization is performing one or more of the following roles:'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paginate through results\n",
        "for result in index.paginate(vector_query, page_size=1):\n",
        "    print(result[0][\"chunk_id\"], result[0][\"vector_distance\"], flush=True)"
      ],
      "metadata": {
        "id": "-vT4bTYB5h74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9bb68a-2632-4629-b075-b32bdce4c1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 0.344000458717\n",
            "9 0.344615459442\n",
            "7 0.346010804176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from redisvl.query.filter import Text\n",
        "\n",
        "query = \"What is TCC?\"\n",
        "\n",
        "query_embedding = vectorizer.embed(query)\n",
        "\n",
        "text_filter = Text(\"content\") % \"Social Security\"\n",
        "\n",
        "vector_query = VectorQuery(\n",
        "    vector=query_embedding,\n",
        "    vector_field_name=\"text_embedding\",\n",
        "    num_results=3,\n",
        "    return_fields=[\"chunk_id\", \"content\"],\n",
        "    return_score=True,\n",
        "    filter_expression=text_filter\n",
        ")\n",
        "\n",
        "# show the raw redis query\n",
        "str(vector_query)"
      ],
      "metadata": {
        "id": "t9MjgGiCLLqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4f49b803-f5aa-4275-fdef-a134c1f4e3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@content:(Social Security)=>[KNN 3 @text_embedding $vector AS vector_distance] RETURN 3 chunk_id content vector_distance SORTBY vector_distance ASC DIALECT 2 LIMIT 0 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# execute the query with RedisVL\n",
        "index.query(vector_query)"
      ],
      "metadata": {
        "id": "ZXci2AeGUMtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054cb33f-d370-4e83-d22b-d85d4a8fd98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'chunk:9',\n",
              "  'vector_distance': '0.344615459442',\n",
              "  'chunk_id': '9',\n",
              "  'content': 'Select the role of Transmitter on your application. Note: The TCC for a Transmitter can be used to transmit your own returns and others. You may not use an Issuer TCC to transmit information returns for others.\\n\\n11\\n\\nPublication 5718\\n\\n1.3.3 Third-Party Transmitters\\n\\nIf you do not have an in-house programmer familiar with XML or do not wish to purchase A2A software that is certified to support the information returns that you plan to file, you can file through a Third-Party Transmitter or use the online Taxpayer Portal. Visit www.irs.gov/ iris for additional information.\\n\\nOnly those persons listed as an Authorized User on the IRIS Application for TCC qualify to receive information about a Receipt ID associated with a TCC listed on that application.\\n\\nIf your Third-Party Transmitter needs technical assistance regarding a Receipt ID associated with records that were submitted on behalf of your organization, they should contact the Help Desk.\\n\\nWhen filing through a Third-Party Transmitter obtain the following for each submission filed on your behalf:\\n\\nA copy of all electronic records within each submission, along with the Receipt ID for the transmission in which they were filed.\\n\\nThe transmission Acknowledgement that includes the Status that is returned when processing is complete (Accepted, Accepted With Errors, Partially Accepted, Rejected) and a detailed list of errors, if any.\\n\\nNote: The items cited above are critical to your ability to make corrections should your Third- party Transmitter go out of business or be otherwise unavailable to file corrections on your behalf.\\n\\n1.3.4 Things you need to know before completing the IRIS\\n\\nA responsible official (RO) initiates and submits the IRIS Application for TCC electronically. Each RO must sign the terms of agreement using their five-digit PIN they created when they initially accessed the system. An application will receive a tracking number after saving it. Completing the application in a single session isn’t a requirement.\\n\\nThe following information is necessary to complete each application:\\n\\nFirm’s business structure\\n\\nFirm’s (EIN) (the system doesn’t allow firms to use a Social Security Number (SSN) or Individual Taxpayer Identification Number (ITIN)\\n\\nFirm’s legal business name and business type\\n\\nFirm’s doing business as name when it’s different from the legal business name\\n\\nBusiness phone (phone country code and phone number)\\n\\nBusiness address (this must be a physical location, not a post office box)'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82-AbKHxItif"
      },
      "source": [
        "# Building a RAG Pipeline from Scratch\n",
        "We're going to build a complete RAG pipeline from scratch incorporating the following components:\n",
        "\n",
        "- Standard retrieval and chat completion\n",
        "- Dense content representation to improve accuracy\n",
        "- Query re-writing to improve accuracy\n",
        "- Semantic caching to improve performance\n",
        "- Conversational session history to improve personalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6BsbxUG7kVc"
      },
      "outputs": [],
      "source": [
        "#@title Setup RedisVL *AsyncSearchIndex*\n",
        "\n",
        "from redis.asyncio import Redis\n",
        "from redisvl.index import AsyncSearchIndex\n",
        "\n",
        "# Create Redis client\n",
        "redis_client = Redis(\n",
        "    host=REDIS_HOST,\n",
        "    port=REDIS_PORT,\n",
        "    password=REDIS_PASSWORD\n",
        ")\n",
        "\n",
        "index = AsyncSearchIndex(index.schema, redis_client)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup VertexAI Generative Model with Safety Settings\n",
        "from vertexai.generative_models import GenerativeModel, Part, HarmCategory, HarmBlockThreshold\n",
        "\n",
        "\n",
        "model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
        "\n",
        "# Define safety settings\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "}\n",
        "\n",
        "# Define generation config\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 2048,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 1\n",
        "}"
      ],
      "metadata": {
        "id": "sSbXjA896Ami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Retrieval Augmented Generation\n",
        "\n",
        "Below we build a simple RAG pipeline with three helper methods:\n",
        "\n",
        "\n",
        "*   `answer_question` -- full RAG operation\n",
        "    * `retrieve_context` -- search Redis for relevant sources\n",
        "    * `promptify`  -- combine system instructions, user question, and sources\n",
        "\n"
      ],
      "metadata": {
        "id": "_Ep2DbPB_Rmu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmma7Cjd7kZ9"
      },
      "outputs": [],
      "source": [
        "async def answer_question(index: AsyncSearchIndex, query: str):\n",
        "    \"\"\"Answer the user's question\"\"\"\n",
        "\n",
        "    SYSTEM_PROMPT = \"\"\"You are a helpful tax analyst assistant that has access\n",
        "    to publications from the IRS\n",
        "    \"\"\"\n",
        "\n",
        "    query_vector = vectorizer.embed(query)\n",
        "\n",
        "    # Fetch context from Redis using vector search\n",
        "    context = await retrieve_context(index, query_vector)\n",
        "\n",
        "    prompt = f'''\n",
        "    System: {SYSTEM_PROMPT}\n",
        "    User: {promptify(query, context)}\n",
        "    '''\n",
        "\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False\n",
        "    )\n",
        "    # Response provided by LLM\n",
        "    if(responses.candidates[0].finish_reason.value == 1):\n",
        "        return(responses.candidates[0].content.parts[0].text)\n",
        "    else:\n",
        "        return(f\"Content has been blocked for {responses.candidates[0].finish_reason.name} reasons.\")\n",
        "\n",
        "\n",
        "async def retrieve_context(index: AsyncSearchIndex, query_vector) -> str:\n",
        "    \"\"\"Fetch the relevant context from Redis using vector search\"\"\"\n",
        "    results = await index.query(\n",
        "        VectorQuery(\n",
        "            vector=query_vector,\n",
        "            vector_field_name=\"text_embedding\",\n",
        "            return_fields=[\"content\"],\n",
        "            num_results=3\n",
        "        )\n",
        "    )\n",
        "    content = \"\\n\".join([result[\"content\"] for result in results])\n",
        "    return content\n",
        "\n",
        "\n",
        "def promptify(query: str, context: str) -> str:\n",
        "    return f'''Use the provided context below derived from public documenation to answer the user's question. If you can't answer the user's\n",
        "    question, based on the context; do not guess. Do your best finding the answer in the context, but if there is no context at all,\n",
        "    respond with \"I don't know\".\n",
        "\n",
        "    User question:\n",
        "\n",
        "    {query}\n",
        "\n",
        "    Helpful context:\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Answer:\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIaYNgNxA4D1"
      },
      "outputs": [],
      "source": [
        "# Generate a list of questions\n",
        "questions = [\n",
        "    \"What is TCC?\",\n",
        "    \"Who should apply for an IRIS TCC?\",\n",
        "    \"What is a JWK?\",\n",
        "    \"Should I buy a yacht??\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy7rh-stIIii"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "results = await asyncio.gather(*[\n",
        "    answer_question(index, question) for question in questions\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for question, result in zip(questions,results):\n",
        "  print(question+\": \\n\"+result+\"\\n\\n\")"
      ],
      "metadata": {
        "id": "T_HZnaBo6ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6cecf5-0366-459f-becd-ced3bb6a4cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is TCC?: \n",
            "TCC stands for Transmitter Control Code. It is a five-character alphanumeric code that begins with the letter 'D' and is assigned to businesses that have applied for and been approved to use the IRS's IRIS system to transmit information returns.\n",
            "\n",
            "\n",
            "Who should apply for an IRIS TCC?: \n",
            "If you are transmitting information returns to the IRS or if you are developing software to file information returns electronically, you must apply for one or more TCCs using the IRIS Application for TCC available online.\n",
            "\n",
            "\n",
            "What is a JWK?: \n",
            "A JSON Web Key (JWK) is a cryptographic key that is represented in JSON format. It contains a public key that validates the API consumer application. JWKs will have the following criteria:\n",
            "\n",
            "JWKs should contain a public key using RSA algorithm. RSA provides a key ID for key matching purposes.\n",
            "\n",
            "Should contain X.509 certificate using both “x5t” (X.509 SHA-1 Thumbprint) and “x5c” (X.509 certificate Chain) parameters.\n",
            "\n",
            "You are not allowed to use self-signed certificates.\n",
            "\n",
            "You can use the same public certificate as used for other IRS programs such as MeF or AIR.\n",
            "\n",
            "For more information on Digital Certificates visit Digital Certificates | Internal Revenue Service\n",
            "\n",
            "The set of JWK attributes need to be pasted into the JSON Web Key (JWK) section of your application following these guidelines:\n",
            "\n",
            "Must be in the order listed below\n",
            "\n",
            "Remove any attribute names not in the list below\n",
            "\n",
            "Paste the full JWK including all the beginning ‘{‘ and ending curly braces ‘}’ to avoid errors\n",
            "\n",
            "A text editing tool may be useful when rearranging and/or removing attributes not listed below\n",
            "\n",
            "Please refer to ‘Figure 1-1’ for a JWK example\n",
            "\n",
            "The attributes expected in JWK are:\n",
            "\n",
            "{\n",
            "\n",
            "“kty”: Key Type (must be RSA)\n",
            "\n",
            "{\n",
            "\n",
            "“kid”: Key ID\n",
            "\n",
            "{\n",
            "\n",
            "“use”: “sig” Public Key Use\n",
            "\n",
            "{\n",
            "\n",
            "“n”: the modulus\n",
            "\n",
            "{\n",
            "\n",
            "“e”: “AQAB” the public exponent\n",
            "\n",
            "{\n",
            "\n",
            "“x5c”: X. 509 Certificate Chain\n",
            "\n",
            "{\n",
            "\n",
            "“x5t”: X.509 Certificate SHA-1 Thumbprint\n",
            "Note: if any of the above attributes are missing from the JWK, the JWK will be invalid. Please refer to Figure 1-1, which contains an example of an RSA key represented as JWKs. Paste the full JWK including the beginning ‘{‘ and ending curly braces ‘}’ to avoid errors. If there are no errors, you will see the Submission Complete page and you will be able to view the issued Client ID.\n",
            "\n",
            "\n",
            "Should I buy a yatch??: \n",
            "I don't know\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve performance and cut costs with LLM Semantic Caching"
      ],
      "metadata": {
        "id": "TN3Ok2zJMhdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from redis import Redis\n",
        "from redisvl.extensions.llmcache import SemanticCache\n",
        "\n",
        "# Create Redis client\n",
        "redis_client = Redis(\n",
        "  host=REDIS_HOST,\n",
        "  port=REDIS_PORT,\n",
        "  password=REDIS_PASSWORD\n",
        ")\n",
        "\n",
        "# Create the Semantic Cache\n",
        "llmcache = SemanticCache(\n",
        "    name=\"llmcache\",\n",
        "    vectorizer=vectorizer,\n",
        "    redis_client=redis_client,\n",
        "    ttl=120,\n",
        "    distance_threshold=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "QzX8lQ35Mpee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import wraps\n",
        "\n",
        "\n",
        "# Create an LLM caching decorator\n",
        "def cache(func):\n",
        "    @wraps(func)\n",
        "    async def wrapper(index, query_text, *args, **kwargs):\n",
        "        query_vector = llmcache._vectorizer.embed(query_text)\n",
        "\n",
        "        # Check the cache with the vector\n",
        "        if result := llmcache.check(vector=query_vector):\n",
        "            return result[0]['response']\n",
        "\n",
        "        response = await func(index, query_text, query_vector=query_vector)\n",
        "        llmcache.store(query_text, response, query_vector)\n",
        "        return response\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@cache\n",
        "async def answer_question(index: AsyncSearchIndex, query: str, **kwargs):\n",
        "    \"\"\"Answer the user's question\"\"\"\n",
        "\n",
        "    SYSTEM_PROMPT = \"\"\"You are a helpful tax analyst assistant that has access\n",
        "    to publications from the IRS\n",
        "    \"\"\"\n",
        "\n",
        "    # Fetch context from Redis using vector search\n",
        "    context = await retrieve_context(index, kwargs[\"query_vector\"])\n",
        "\n",
        "    prompt = f'''\n",
        "    System: {SYSTEM_PROMPT}\n",
        "    User: {promptify(query, context)}\n",
        "    '''\n",
        "\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False\n",
        "    )\n",
        "    # Response provided by LLM\n",
        "    if(responses.candidates[0].finish_reason.value == 1):\n",
        "        return(responses.candidates[0].content.parts[0].text)\n",
        "    else:\n",
        "        return(f\"Content has been blocked for {responses.candidates[0].finish_reason.name} reasons.\")\n"
      ],
      "metadata": {
        "id": "vaovoOKbMrSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "a4d6PJG01hcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a JWK?\"\n",
        "\n",
        "startTime = datetime.now()\n",
        "await answer_question(index, query)\n",
        "print(f\"Total time: {datetime.now() - startTime}\")"
      ],
      "metadata": {
        "id": "yAMpnoVIP7G1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471eee81-4be4-444a-cb7a-cb6d5a49732d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0:00:01.589413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now try again with semantic caching enabled!\n",
        "query = \"What's a JWK?\"\n",
        "\n",
        "startTime = datetime.now()\n",
        "await answer_question(index, query)\n",
        "print(f\"Total time: {datetime.now() - startTime}\")"
      ],
      "metadata": {
        "id": "aepPokugQBNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b1b086-9f67-4eb2-db02-9ff005a06fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0:00:00.140257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "async def respond(message, history):\n",
        "    print(message)\n",
        "    result = await answer_question(index, message)\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "gr.ChatInterface(respond).launch()"
      ],
      "metadata": {
        "id": "H6jxgpzWA2Ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "6a7844f8-2ba8-4882-c2ec-40661e0e7855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13:50:12 httpx INFO   HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
            "13:50:14 httpx INFO   HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
            "13:50:14 httpx INFO   HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
            "13:50:14 httpx INFO   HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "13:50:14 httpx INFO   HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "13:50:15 httpx INFO   HTTP Request: POST https://api.gradio.app/gradio-initiated-analytics/ \"HTTP/1.1 200 OK\"\n",
            "13:50:16 httpx INFO   HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "13:50:16 httpx INFO   HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64 \"HTTP/1.1 200 OK\"\n",
            "Running on public URL: https://587c27df19585213af.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "13:50:17 httpx INFO   HTTP Request: HEAD https://587c27df19585213af.gradio.live \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://587c27df19585213af.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}